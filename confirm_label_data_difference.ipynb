{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9c3b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d5c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import random_split\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e9e989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875cac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82115\n"
     ]
    }
   ],
   "source": [
    "# data_dir_path = './tiny-imagenet-200'\n",
    "data_dir_path = '/home/yohei/project/cs760/tiny-imagenet-200'\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "def data_transform():\n",
    "    return T.Compose([\n",
    "        T.Resize(64),\n",
    "        T.ColorJitter(brightness=0.5),\n",
    "        T.RandomAffine(degrees=15, translate=(0.08,0.08), scale=(0.8,1.2), shear=10),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        #T.RandomResizedCrop(64,scale=(0.7, 1.4)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# data formatting (only one time run at the beginning)\n",
    "def format_val():\n",
    "    val_dir = data_dir_path + '/val'\n",
    "    print(\"Formatting: {}\".format(val_dir))\n",
    "    val_annotations = \"{}/val_annotations.txt\".format(val_dir)\n",
    "    val_dict = {}\n",
    "    with open(val_annotations, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            assert(len(line) == 6)\n",
    "            wnind = line[1]\n",
    "            img_name = line[0]\n",
    "            boxes = '\\t'.join(line[2:])\n",
    "            if wnind not in val_dict:\n",
    "                val_dict[wnind] = []\n",
    "            entries = val_dict[wnind]\n",
    "            entries.append((img_name, boxes))\n",
    "    assert(len(val_dict) == 200)\n",
    "    for wnind, entries in val_dict.items():\n",
    "        val_wnind_dir = \"{}/{}\".format(val_dir, wnind)\n",
    "        val_images_dir = \"{}/images\".format(val_dir)\n",
    "        val_wnind_images_dir = \"{}/images\".format(val_wnind_dir)\n",
    "        os.mkdir(val_wnind_dir)\n",
    "        os.mkdir(val_wnind_images_dir)\n",
    "        wnind_boxes = \"{}/{}_boxes.txt\".format(val_wnind_dir, wnind)\n",
    "        f = open(wnind_boxes, \"w\")\n",
    "        for img_name, box in entries:\n",
    "            source = \"{}/{}\".format(val_images_dir, img_name)\n",
    "            dst = \"{}/{}\".format(val_wnind_images_dir, img_name)\n",
    "            os.system(\"cp {} {}\".format(source, dst))\n",
    "            f.write(img_name+'\\\\'+box+'\\\\'+'n')\n",
    "        f.close()\n",
    "    # os.system(\"rm -rf %s\" % val_images_dir)\n",
    "    #print(\"Cleaning up: %s\" % val_images_dir)\n",
    "    print(\"Formatting val done\")\n",
    "    \n",
    "    \n",
    "# create dataset object\n",
    "train_dataset = ImageFolder(data_dir_path + '/train', transform=data_transform())\n",
    "test_dataset = ImageFolder(data_dir_path + '/test', transform=T.ToTensor())\n",
    "\n",
    "# Texting label (only one time run at the beginning)\n",
    "d = {}\n",
    "\n",
    "f = open(data_dir_path+'/words.txt','r') \n",
    "while(1):\n",
    "    try:\n",
    "        key, val = f.readline().split(\"\\t\")\n",
    "        d[key] = val[:-1]\n",
    "    except Exception:\n",
    "        break\n",
    "\n",
    "print(len(d))\n",
    "\n",
    "tiny_imagenet_label = train_dataset.classes\n",
    "for i in range(len(tiny_imagenet_label)):\n",
    "    train_dataset.classes[i] = d[tiny_imagenet_label[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "741d237f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tiny_imagenet_label[0]) # len(tiny_imagenet_label) == 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3849806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /home/yohei/project/cs760/cifar100data/cifar-100-python/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b36a08fb67240dbab0dfcba08fd73c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR100\n",
    "## you can change the directory for downloading cifar-100 data\n",
    "data_dir_path_cifar = '/home/yohei/project/cs760/cifar100data/cifar-100-python'\n",
    "train_data_cifar = CIFAR100(download=True,root=data_dir_path_cifar)\n",
    "test_data_cifar = CIFAR100(root=data_dir_path_cifar,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84c5766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_label = train_data_cifar.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0f13fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cifar_label[0]) # len(cifar_label) == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae9016ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bee\n",
      "mushroom\n",
      "orange\n",
      "plate\n",
      "snail\n",
      "tractor\n"
     ]
    }
   ],
   "source": [
    "match_count = 0\n",
    "unmatch_count = 0\n",
    "\n",
    "for label_c in cifar_label:\n",
    "    if(label_c in tiny_imagenet_label):\n",
    "        match_count += 1\n",
    "        print(label_c)\n",
    "    else:\n",
    "        unmatch_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f65e2bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 94\n"
     ]
    }
   ],
   "source": [
    "print(match_count, unmatch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5b9dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a344f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c1221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89888c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421648b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d0b07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f779fa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4aa56d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c160d872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c121d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613b69dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e99c77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
