{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98195ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc97817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "# from torchvision.transforms import ToTensor\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import random_split\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96509f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning off\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# default font\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# default graph size\n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "\n",
    "# default graph grid\n",
    "# plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# numpy precision\n",
    "np.set_printoptions(suppress=True, precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733c64c",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb69c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb29a2d",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = './tiny-imagenet-200'\n",
    "\n",
    "# data augmentation\n",
    "\n",
    "def data_transform():\n",
    "    return T.Compose([\n",
    "        T.Resize(64),\n",
    "        T.ColorJitter(brightness=0.5),\n",
    "        T.RandomAffine(degrees=15, translate=(0.08,0.08), scale=(0.8,1.2), shear=10),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        #T.RandomResizedCrop(64,scale=(0.7, 1.4)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# data formatting (only one time run at the beginning)\n",
    "def format_val():\n",
    "    val_dir = data_dir_path + '/val'\n",
    "    print(\"Formatting: {}\".format(val_dir))\n",
    "    val_annotations = \"{}/val_annotations.txt\".format(val_dir)\n",
    "    val_dict = {}\n",
    "    with open(val_annotations, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            assert(len(line) == 6)\n",
    "            wnind = line[1]\n",
    "            img_name = line[0]\n",
    "            boxes = '\\t'.join(line[2:])\n",
    "            if wnind not in val_dict:\n",
    "                val_dict[wnind] = []\n",
    "            entries = val_dict[wnind]\n",
    "            entries.append((img_name, boxes))\n",
    "    assert(len(val_dict) == 200)\n",
    "    for wnind, entries in val_dict.items():\n",
    "        val_wnind_dir = \"{}/{}\".format(val_dir, wnind)\n",
    "        val_images_dir = \"{}/images\".format(val_dir)\n",
    "        val_wnind_images_dir = \"{}/images\".format(val_wnind_dir)\n",
    "        os.mkdir(val_wnind_dir)\n",
    "        os.mkdir(val_wnind_images_dir)\n",
    "        wnind_boxes = \"{}/{}_boxes.txt\".format(val_wnind_dir, wnind)\n",
    "        f = open(wnind_boxes, \"w\")\n",
    "        for img_name, box in entries:\n",
    "            source = \"{}/{}\".format(val_images_dir, img_name)\n",
    "            dst = \"{}/{}\".format(val_wnind_images_dir, img_name)\n",
    "            os.system(\"cp {} {}\".format(source, dst))\n",
    "            f.write(img_name+'\\\\'+box+'\\\\'+'n')\n",
    "        f.close()\n",
    "    # os.system(\"rm -rf %s\" % val_images_dir)\n",
    "    #print(\"Cleaning up: %s\" % val_images_dir)\n",
    "    print(\"Formatting val done\")\n",
    "    \n",
    "    \n",
    "# create dataset object\n",
    "train_dataset = ImageFolder(data_dir_path + '/train', transform=data_transform())\n",
    "test_dataset = ImageFolder(data_dir_path + '/test', transform=T.ToTensor())\n",
    "\n",
    "# Texting label (only one time run at the beginning)\n",
    "d = {}\n",
    "\n",
    "f = open(data_dir_path+'/words.txt','r') \n",
    "while(1):\n",
    "    try:\n",
    "        key, val = f.readline().split(\"\\t\")\n",
    "        d[key] = val[:-1]\n",
    "    except Exception:\n",
    "        break\n",
    "\n",
    "print(len(d))\n",
    "\n",
    "# TODO: replace with our trained model later\n",
    "pretrain_wv = gensim.downloader.load('glove-wiki-gigaword-50')\n",
    "\n",
    "aa = train_dataset.classes\n",
    "for i in range(len(aa)):\n",
    "    label_terms = d[aa[i]].split(', ')\n",
    "    label_vector = torch.zeros(50)  # TODO: change to 500 (size of word vector) later\n",
    "    num_terms = 0\n",
    "    for term in label_terms:\n",
    "        if term in pretrain_wv:\n",
    "            label_vector += pretrain_wv[term]\n",
    "            num_terms += 1\n",
    "    if num_terms > 0:\n",
    "        label_vector /= num_terms\n",
    "    train_dataset.classes[i] = label_vector\n",
    "    \n",
    "def get_embeddings(labels):\n",
    "    return torch.vstack([train_dataset.classes[i] for i in labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 4\n",
    "torch.manual_seed(random_seed);\n",
    "\n",
    "val_size = 10000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a098248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, label):\n",
    "    print('Label: ', train_dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    plt.imshow(img.permute(1, 2, 0))\n",
    "    \n",
    "show_example(*train_dataset[55555])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e64987",
   "metadata": {},
   "source": [
    "# def of common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f36fc",
   "metadata": {},
   "source": [
    "## eval_loss loss calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661633df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失計算用\n",
    "def eval_loss(loader, device, net, criterion):\n",
    "  \n",
    "    # データローダーから最初の1セットを取得する\n",
    "    for images, labels in loader:\n",
    "        break\n",
    "\n",
    "    # デバイスの割り当て\n",
    "    inputs = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    #  損失計算\n",
    "    loss = criterion(outputs, get_embeddings(labels), torch.ones(len(outputs)))\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Cosine loss for bimodal model. We actually want 1-similarity as \n",
    "# the similarity will be 0 when the vectors are orthogonal and close \n",
    "# to 1 when the same. \n",
    "def cosine_loss(vec1, vec2):\n",
    "    return 1 - F.cosine_similarity(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae2c861",
   "metadata": {},
   "source": [
    "## fit learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8dc98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history):\n",
    "\n",
    "    # tqdmライブラリのインポート\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    base_epochs = len(history)\n",
    "  \n",
    "    for epoch in range(base_epochs, num_epochs+base_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        #訓練フェーズ\n",
    "        net.train()\n",
    "        count = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            count += len(labels)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 勾配の初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 予測計算\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, get_embeddings(labels), torch.ones(len(outputs)))\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 勾配計算\n",
    "            loss.backward()\n",
    "\n",
    "            # パラメータ修正\n",
    "            optimizer.step()\n",
    "\n",
    "            # 予測値算出\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "            # 正解件数算出\n",
    "            train_acc += (predicted == labels).sum().item()\n",
    "\n",
    "            # 損失と精度の計算\n",
    "            avg_train_loss = train_loss / count\n",
    "            avg_train_acc = train_acc / count\n",
    "\n",
    "        #予測フェーズ\n",
    "        net.eval()\n",
    "        count = 0\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            count += len(labels)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 予測計算\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, get_embeddings(labels), torch.ones(len(outputs)))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # 予測値算出\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "            # 正解件数算出\n",
    "            val_acc += (predicted == labels).sum().item()\n",
    "\n",
    "            # 損失と精度の計算\n",
    "            avg_val_loss = val_loss / count\n",
    "            avg_val_acc = val_acc / count\n",
    "    \n",
    "        print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {avg_train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {avg_val_acc:.5f}')\n",
    "        item = np.array([epoch+1, avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc])\n",
    "        history = np.vstack((history, item))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a153e96e",
   "metadata": {},
   "source": [
    "## eval_history log analysis of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ログ解析\n",
    "\n",
    "def evaluate_history(history):\n",
    "    #損失と精度の確認\n",
    "    print(f'Initial: loss: {history[0,3]:.5f} accuracy: {history[0,4]:.5f}') \n",
    "    print(f'Final: loss: {history[-1,3]:.5f} accuracy: {history[-1,4]:.5f}' )\n",
    "\n",
    "    num_epochs = len(history)\n",
    "    unit = num_epochs / 10\n",
    "\n",
    "    # 学習曲線の表示 (損失)\n",
    "    plt.figure(figsize=(9,8))\n",
    "    plt.plot(history[:,0], history[:,1], 'b', label='Training')\n",
    "    plt.plot(history[:,0], history[:,3], 'k', label='Test(Val)')\n",
    "    plt.xticks(np.arange(0,num_epochs+1, unit))\n",
    "    plt.xlabel('# of recursion')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 学習曲線の表示 (精度)\n",
    "    plt.figure(figsize=(9,8))\n",
    "    plt.plot(history[:,0], history[:,2], 'b', label='Training')\n",
    "    plt.plot(history[:,0], history[:,4], 'k', label='Test(Val)')\n",
    "    plt.xticks(np.arange(0,num_epochs+1,unit))\n",
    "    plt.xlabel('# of recursion')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Learning Curve (Accuracy)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d207f5c2",
   "metadata": {},
   "source": [
    "##  show_images_labels show image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e5253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# イメージとラベル表示\n",
    "def show_images_labels(loader, classes, net, device):\n",
    "\n",
    "    # データローダーから最初の1セットを取得する\n",
    "    for images, labels in loader:\n",
    "        break\n",
    "    # 表示数は50個とバッチサイズのうち小さい方\n",
    "    n_size = min(len(images), 20)\n",
    "\n",
    "    if net is not None:\n",
    "      # デバイスの割り当て\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "      # 予測計算\n",
    "        outputs = net(inputs)\n",
    "        predicted = torch.max(outputs,1)[1]\n",
    "      #images = images.to('cpu')\n",
    "\n",
    "    # 最初のn_size個の表示\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    for i in range(n_size):\n",
    "        ax = plt.subplot(4, 5, i + 1)\n",
    "        label_name = classes[labels[i]]\n",
    "        # netがNoneでない場合は、予測結果もタイトルに表示する\n",
    "        if net is not None:\n",
    "            predicted_name = classes[predicted[i]]\n",
    "          # 正解かどうかで色分けをする\n",
    "            if label_name == predicted_name:\n",
    "                c = 'green'\n",
    "            else:\n",
    "                c = 'blue'\n",
    "            ax.set_title(label_name + ':' + predicted_name, c=c, fontsize=20)\n",
    "        # netがNoneの場合は、正解ラベルのみ表示\n",
    "        else:\n",
    "            ax.set_title(label_name, fontsize=20)\n",
    "        # TensorをNumPyに変換\n",
    "        image_np = images[i].numpy().copy()\n",
    "        # 軸の順番変更 (channel, row, column) -> (row, column, channel)\n",
    "        img = np.transpose(image_np, (1, 2, 0))\n",
    "        # 値の範囲を[-1, 1] -> [0, 1]に戻す\n",
    "        img = (img + 1)/2\n",
    "        # 結果表示\n",
    "        plt.imshow(img)\n",
    "        ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad76813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch乱数固定用\n",
    "\n",
    "def torch_seed(seed=123):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c03a758",
   "metadata": {},
   "source": [
    "## data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f396cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1, label1 = train_dataset[0]\n",
    "image2, label2 = train_dataset[1330]\n",
    "\n",
    "print(image1.shape)\n",
    "print(image2.shape)\n",
    "print(label1)\n",
    "print(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd89c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "\n",
    "# size of batch\n",
    "batch_size = 100\n",
    "# batch_size = 512\n",
    "\n",
    "# DataLoarder of Training data\n",
    "train_loader2 = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# DataLoarder of Test data\n",
    "test_loader2 = DataLoader(val_ds,  batch_size=batch_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae9cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader2から1セット取得\n",
    "for images2, labels2 in train_loader2:\n",
    "    break\n",
    "\n",
    "# それぞれのshape確認\n",
    "print(images2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d70d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベル定義\n",
    "classes = train_dataset.classes\n",
    "\n",
    "# 検証データ最初の50個の表示\n",
    "show_images_labels(test_loader2, classes, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b2b95",
   "metadata": {},
   "source": [
    "# Def Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36812f1b",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a66834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output degree: 出力次元数\n",
    "# number of classes: 分類先クラス数\n",
    "# n_output = len(classes)\n",
    "n_output = 50  # TODO: change to 500 (size of word vector) later\n",
    "\n",
    "# number of nodes of hidden layer 隠れ層のノード数\n",
    "n_hidden = 256 \n",
    "\n",
    "print(f'n_hidden: {n_hidden} n_output: {n_output}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12756e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_output, n_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d((2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.l1 = nn.Linear(2048, n_hidden) # 16*32*32\n",
    "        self.l2 = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            self.conv1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            \n",
    "            self.conv2,\n",
    "            self.relu,\n",
    "            self.maxpool,          \n",
    "            \n",
    "            self.conv3,\n",
    "            self.relu,\n",
    "            self.maxpool,  \n",
    "            \n",
    "#             self.flatten,\n",
    "#             self.l1,\n",
    "#             self.relu,\n",
    "#             self.l2,\n",
    "            \n",
    "#             nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 16, 32, 32\n",
    "\n",
    "#             nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 16, 16, 16 \n",
    "\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 32, 8, 8 \n",
    "\n",
    "\n",
    "#             nn.Flatten(), # 16 x 2048\n",
    "#             nn.Linear(2048, n_hidden),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(n_hidden, n_output),\n",
    "#             self.conv1,# out: 16, 64, 64\n",
    "#             self.relu,# out: 16, 64, 64\n",
    "#             self.conv2,# out: 16, 64, 64\n",
    "#             self.relu,# out: 16, 64, 64\n",
    "#             self.maxpool # out: 16, 32, 32\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "           self.l1,\n",
    "           self.relu,\n",
    "           self.l2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.flatten(x1)\n",
    "        x3 = self.classifier(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d8e2d4",
   "metadata": {},
   "source": [
    "### Create model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13254fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instanceモデルインスタンス生成\n",
    "net = CNN(n_output, n_hidden).to(device)\n",
    "\n",
    "# loss function: cross entropy 損失関数： 交差エントロピー関数\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "# learning ratio: 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# optimizer: gradient 最適化関数: 勾配降下法\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128b0ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of model: モデルの概要表示\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816d4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of model:モデルのサマリー表示\n",
    "\n",
    "summary(net,(100,3,64,64),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc loss: 損失計算\n",
    "loss = eval_loss(test_loader2, device, net, criterion)\n",
    "\n",
    "# visualize calc loss: 損失の計算グラフ可視化\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "display(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8367f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init randam, 乱数初期化\n",
    "torch_seed()\n",
    "\n",
    "# create model instanceモデルインスタンス生成\n",
    "net = CNN(n_output, n_hidden).to(device)\n",
    "\n",
    "# loss function: cross entropy損失関数： 交差エントロピー関数\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.CosineEmbeddingLoss()\n",
    "\n",
    "# learning step 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# optimizser 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# epock 繰り返し回数\n",
    "num_epochs = 5\n",
    "\n",
    "# output 評価結果記録用\n",
    "history2 = np.zeros((0,5))\n",
    "\n",
    "# learning: 学習\n",
    "history2 = fit(net, optimizer, criterion, num_epochs, train_loader2, test_loader2, device, history2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97823475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "\n",
    "evaluate_history(history2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2825e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の50個の表示\n",
    "\n",
    "show_images_labels(test_loader2, classes, net, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d5e358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e902717c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
