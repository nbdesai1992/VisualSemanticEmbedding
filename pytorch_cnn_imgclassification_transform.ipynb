{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import japanize_matplotlib\n",
    "from IPython.display import display\n",
    "\n",
    "matplotlib.rcParams['figure.facecolor'] = '#ffffff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "import torchvision.datasets as datasets\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as T # Compose, ToTensor, RandomCrop, RandomHorizontalFlip, RandomRotation, RandomApply\n",
    "from torch.utils.data import random_split\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning off\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# default font\n",
    "plt.rcParams['font.size'] = 14\n",
    "\n",
    "# default graph size\n",
    "plt.rcParams['figure.figsize'] = (4,4)\n",
    "\n",
    "# default graph grid\n",
    "# plt.rcParams['axes.grid'] = True\n",
    "\n",
    "# numpy precision\n",
    "np.set_printoptions(suppress=True, precision=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_path = 'D:/tiny-imagenet-200'\n",
    "\n",
    "def data_transform():\n",
    "    return T.Compose([\n",
    "        T.Resize(64),\n",
    "        T.ColorJitter(brightness=(0.75,1.5)),\n",
    "        T.RandomAffine(degrees=15, translate=(0.08,0.08), scale=(0.8,1.2), shear=10),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        #T.RandomResizedCrop(64,scale=(0.7, 1.4)),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# data formatting (only one time run at the beginning)\n",
    "def format_val():\n",
    "    val_dir = data_dir_path + '/val'\n",
    "    print(\"Formatting: {}\".format(val_dir))\n",
    "    val_annotations = \"{}/val_annotations.txt\".format(val_dir)\n",
    "    val_dict = {}\n",
    "    with open(val_annotations, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            assert(len(line) == 6)\n",
    "            wnind = line[1]\n",
    "            img_name = line[0]\n",
    "            boxes = '\\t'.join(line[2:])\n",
    "            if wnind not in val_dict:\n",
    "                val_dict[wnind] = []\n",
    "            entries = val_dict[wnind]\n",
    "            entries.append((img_name, boxes))\n",
    "    assert(len(val_dict) == 200)\n",
    "    for wnind, entries in val_dict.items():\n",
    "        val_wnind_dir = \"{}/{}\".format(val_dir, wnind)\n",
    "        val_images_dir = \"{}/images\".format(val_dir)\n",
    "        val_wnind_images_dir = \"{}/images\".format(val_wnind_dir)\n",
    "        os.mkdir(val_wnind_dir)\n",
    "        os.mkdir(val_wnind_images_dir)\n",
    "        wnind_boxes = \"{}/{}_boxes.txt\".format(val_wnind_dir, wnind)\n",
    "        f = open(wnind_boxes, \"w\")\n",
    "        for img_name, box in entries:\n",
    "            source = \"{}/{}\".format(val_images_dir, img_name)\n",
    "            dst = \"{}/{}\".format(val_wnind_images_dir, img_name)\n",
    "            os.system(\"cp {} {}\".format(source, dst))\n",
    "            f.write(img_name+'\\\\'+box+'\\\\'+'n')\n",
    "        f.close()\n",
    "    # os.system(\"rm -rf %s\" % val_images_dir)\n",
    "    #print(\"Cleaning up: %s\" % val_images_dir)\n",
    "    print(\"Formatting val done\")\n",
    "    \n",
    "    \n",
    "# create dataset object\n",
    "train_dataset = ImageFolder(data_dir_path + '/train', transform=data_transform())\n",
    "test_dataset = ImageFolder(data_dir_path + '/test', transform=T.ToTensor())\n",
    "\n",
    "# Texting label (only one time run at the beginning)\n",
    "d = {}\n",
    "\n",
    "f = open(data_dir_path+'/words.txt','r') \n",
    "while(1):\n",
    "    try:\n",
    "        key, val = f.readline().split(\"\\t\")\n",
    "        d[key] = val[:-1]\n",
    "    except Exception:\n",
    "        break\n",
    "\n",
    "print(len(d))\n",
    "\n",
    "aa = train_dataset.classes\n",
    "for i in range(len(aa)):\n",
    "    train_dataset.classes[i] = d[aa[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 4\n",
    "torch.manual_seed(random_seed);\n",
    "\n",
    "val_size = 10000\n",
    "train_size = len(train_dataset) - val_size\n",
    "\n",
    "train_ds, val_ds = random_split(train_dataset, [train_size, val_size])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(img, label):\n",
    "    print('Label: ', train_dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "    img = img.permute(1, 2, 0)\n",
    "    #print(img.size())\n",
    "    #print(img.min(),img.max())\n",
    "    plt.imshow(img)\n",
    "    \n",
    "show_example(*train_dataset[55555])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# def of common functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_loss loss calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失計算用\n",
    "def eval_loss(loader, device, net, criterion):\n",
    "  \n",
    "    # データローダーから最初の1セットを取得する\n",
    "    for images, labels in loader:\n",
    "        break\n",
    "\n",
    "    # デバイスの割り当て\n",
    "    inputs = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # 予測計算\n",
    "    outputs = net(inputs)\n",
    "\n",
    "    #  損失計算\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, optimizer, criterion, num_epochs, train_loader, test_loader, device, history):\n",
    "\n",
    "    # tqdmライブラリのインポート\n",
    "    from tqdm.notebook import tqdm\n",
    "\n",
    "    base_epochs = len(history)\n",
    "  \n",
    "    for epoch in range(base_epochs, num_epochs+base_epochs):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        #訓練フェーズ\n",
    "        net.train()\n",
    "        count = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader):\n",
    "            count += len(labels)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 勾配の初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 予測計算\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, labels)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            # 勾配計算\n",
    "            loss.backward()\n",
    "\n",
    "            # パラメータ修正\n",
    "            optimizer.step()\n",
    "\n",
    "            # 予測値算出\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "            # 正解件数算出\n",
    "            train_acc += (predicted == labels).sum()\n",
    "\n",
    "            # 損失と精度の計算\n",
    "            avg_train_loss = train_loss / count\n",
    "            avg_train_acc = train_acc / count\n",
    "\n",
    "        #予測フェーズ\n",
    "        net.eval()\n",
    "        count = 0\n",
    "\n",
    "        for inputs, labels in test_loader:\n",
    "            count += len(labels)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # 予測計算\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # 損失計算\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # 予測値算出\n",
    "            predicted = torch.max(outputs, 1)[1]\n",
    "\n",
    "            # 正解件数算出\n",
    "            val_acc += (predicted == labels).sum()\n",
    "\n",
    "            # 損失と精度の計算\n",
    "            avg_val_loss = val_loss / count\n",
    "            avg_val_acc = val_acc / count\n",
    "    \n",
    "        print (f'Epoch [{(epoch+1)}/{num_epochs+base_epochs}], loss: {avg_train_loss:.5f} acc: {avg_train_acc:.5f} val_loss: {avg_val_loss:.5f}, val_acc: {avg_val_acc:.5f}')\n",
    "        item = np.array([epoch+1, avg_train_loss, avg_train_acc, avg_val_loss, avg_val_acc])\n",
    "        history = np.vstack((history, item))\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval_history log analysis of learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習ログ解析\n",
    "\n",
    "def evaluate_history(history):\n",
    "    #損失と精度の確認\n",
    "    print(f'Initial: loss: {history[0,3]:.5f} accuracy: {history[0,4]:.5f}') \n",
    "    print(f'Final: loss: {history[-1,3]:.5f} accuracy: {history[-1,4]:.5f}' )\n",
    "\n",
    "    num_epochs = len(history)\n",
    "    unit = num_epochs / 10\n",
    "\n",
    "    # 学習曲線の表示 (損失)\n",
    "    plt.figure(figsize=(9,8))\n",
    "    plt.plot(history[:,0], history[:,1], 'b', label='Training')\n",
    "    plt.plot(history[:,0], history[:,3], 'k', label='Test(Val)')\n",
    "    plt.xticks(np.arange(0,num_epochs+1, unit))\n",
    "    plt.xlabel('# of recursion')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Learning Curve (Loss)')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 学習曲線の表示 (精度)\n",
    "    plt.figure(figsize=(9,8))\n",
    "    plt.plot(history[:,0], history[:,2], 'b', label='Training')\n",
    "    plt.plot(history[:,0], history[:,4], 'k', label='Test(Val)')\n",
    "    plt.xticks(np.arange(0,num_epochs+1,unit))\n",
    "    plt.xlabel('# of recursion')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Learning Curve (Accuracy)')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  show_images_labels show image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# イメージとラベル表示\n",
    "def show_images_labels(loader, classes, net, device):\n",
    "\n",
    "    # データローダーから最初の1セットを取得する\n",
    "    for images, labels in loader:\n",
    "        break\n",
    "    # 表示数は50個とバッチサイズのうち小さい方\n",
    "    n_size = min(len(images), 20)\n",
    "\n",
    "    if net is not None:\n",
    "      # デバイスの割り当て\n",
    "        inputs = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "      # 予測計算\n",
    "        outputs = net(inputs)\n",
    "        predicted = torch.max(outputs,1)[1]\n",
    "      #images = images.to('cpu')\n",
    "\n",
    "    # 最初のn_size個の表示\n",
    "    plt.figure(figsize=(20, 15))\n",
    "    for i in range(n_size):\n",
    "        ax = plt.subplot(4, 5, i + 1)\n",
    "        label_name = classes[labels[i]]\n",
    "        # netがNoneでない場合は、予測結果もタイトルに表示する\n",
    "        if net is not None:\n",
    "            predicted_name = classes[predicted[i]]\n",
    "          # 正解かどうかで色分けをする\n",
    "            if label_name == predicted_name:\n",
    "                c = 'green'\n",
    "            else:\n",
    "                c = 'blue'\n",
    "            ax.set_title(label_name + ':' + predicted_name, c=c, fontsize=20)\n",
    "        # netがNoneの場合は、正解ラベルのみ表示\n",
    "        else:\n",
    "            ax.set_title(label_name, fontsize=20)\n",
    "        # TensorをNumPyに変換\n",
    "        image_np = images[i].numpy().copy()\n",
    "        # 軸の順番変更 (channel, row, column) -> (row, column, channel)\n",
    "        img = np.transpose(image_np, (1, 2, 0))\n",
    "        # 値の範囲を[-1, 1] -> [0, 1]に戻す\n",
    "        img = (img + 1)/2\n",
    "        # 結果表示\n",
    "        plt.imshow(img)\n",
    "        ax.set_axis_off()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch乱数固定用\n",
    "\n",
    "def torch_seed(seed=123):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.use_deterministic_algorithms = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1, label1 = train_dataset[0]\n",
    "image2, label2 = train_dataset[1330]\n",
    "\n",
    "print(image1.shape)\n",
    "print(image2.shape)\n",
    "print(label1)\n",
    "print(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "\n",
    "# size of batch\n",
    "batch_size = 100\n",
    "\n",
    "# DataLoarder of Training data\n",
    "train_loader2 = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# DataLoarder of Test data\n",
    "test_loader2 = DataLoader(val_ds,  batch_size=batch_size, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader2から1セット取得\n",
    "for images2, labels2 in train_loader2:\n",
    "    break\n",
    "\n",
    "# それぞれのshape確認\n",
    "print(images2.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベル定義\n",
    "classes = train_dataset.classes\n",
    "\n",
    "# 検証データ最初の50個の表示\n",
    "show_images_labels(test_loader2, classes, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Def Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output degree: 出力次元数\n",
    "# number of classes: 分類先クラス数\n",
    "n_output = len(classes)\n",
    "\n",
    "# number of nodes of hidden layer 隠れ層のノード数\n",
    "n_hidden = 256 \n",
    "\n",
    "print(f'n_hidden: {n_hidden} n_output: {n_output}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_output, n_hidden):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d((2,2))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(p=0.3)\n",
    "        self.l1 = nn.Linear(2048, n_hidden) # 16*32*32\n",
    "        self.l2 = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            \n",
    "            self.conv1,\n",
    "            self.relu,\n",
    "            self.maxpool,\n",
    "            \n",
    "            self.conv2,\n",
    "            self.relu,\n",
    "            self.maxpool,          \n",
    "            \n",
    "            self.conv3,\n",
    "            self.relu,\n",
    "            self.maxpool,  \n",
    "            \n",
    "#             self.flatten,\n",
    "#             self.l1,\n",
    "#             self.relu,\n",
    "#             self.l2,\n",
    "            \n",
    "#             nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 16, 32, 32\n",
    "\n",
    "#             nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 16, 16, 16 \n",
    "\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2, 2), # output: 32, 8, 8 \n",
    "\n",
    "\n",
    "#             nn.Flatten(), # 16 x 2048\n",
    "#             nn.Linear(2048, n_hidden),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(n_hidden, n_output),\n",
    "#             self.conv1,# out: 16, 64, 64\n",
    "#             self.relu,# out: 16, 64, 64\n",
    "#             self.conv2,# out: 16, 64, 64\n",
    "#             self.relu,# out: 16, 64, 64\n",
    "#             self.maxpool # out: 16, 32, 32\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "           self.l1,\n",
    "           self.relu,\n",
    "           self.l2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.features(x)\n",
    "        x2 = self.flatten(x1)\n",
    "        x3 = self.classifier(x2)\n",
    "        return x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model instanceモデルインスタンス生成\n",
    "net = CNN(n_output, n_hidden).to(device)\n",
    "\n",
    "# loss function: cross entropy 損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# learning ratio: 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# optimizer: gradient 最適化関数: 勾配降下法\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of model: モデルの概要表示\n",
    "\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of model:モデルのサマリー表示\n",
    "\n",
    "summary(net,(100,3,64,64),depth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc loss: 損失計算\n",
    "loss = eval_loss(test_loader2, device, net, criterion)\n",
    "\n",
    "# visualize calc loss: 損失の計算グラフ可視化\n",
    "g = make_dot(loss, params=dict(net.named_parameters()))\n",
    "display(g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init randam, 乱数初期化\n",
    "torch_seed()\n",
    "\n",
    "# create model instanceモデルインスタンス生成\n",
    "net = CNN(n_output, n_hidden).to(device)\n",
    "\n",
    "# loss function: cross entropy損失関数： 交差エントロピー関数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# learning step 学習率\n",
    "lr = 0.01\n",
    "\n",
    "# optimizser 最適化関数: 勾配降下法\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "\n",
    "# epock 繰り返し回数\n",
    "num_epochs = 1\n",
    "\n",
    "# output 評価結果記録用\n",
    "history2 = np.zeros((0,5))\n",
    "\n",
    "# learning: 学習\n",
    "history2 = fit(net, optimizer, criterion, num_epochs, train_loader2, test_loader2, device, history2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価\n",
    "\n",
    "evaluate_history(history2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最初の50個の表示\n",
    "\n",
    "show_images_labels(test_loader2, classes, net, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
